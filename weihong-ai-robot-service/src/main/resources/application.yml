server:
  port: 8080 # 项目启动端口

spring:
  cassandra:
    contact-points: 127.0.0.1 # Cassandra 集群节点地址（可配置多个，用逗号分隔）
    port: 9042 # 端口号
    local-datacenter: datacenter1 # 必须与集群配置的数据中心名称一致（大小写敏感）
  ai:
    mcp:
      client:
        type: sync # 客户端使用同步通信模式
        request-timeout: 20s # 设置单次请求超时时间
        sse: # SSE (Server-Sent Events) 流式响应配置
          connections: # 定义 SSE 连接端点
            qq-mcp-server: # 自定义连接名称（可任意命名）
              url: http://localhost:8000 # MCP 服务实际地址
#    mcp:
#      client:
#        stdio:
#          servers-configuration: classpath:/mcp-servers-config.json # 指定 MCP 服务的配置文件路径
#        toolcallback:
#          enabled: true # 开启 MCP 客户端的工具回调（Tool Callback）功能
    chat:
      memory:
        repository:
          cassandra:
            keyspace: weihong_ai_robot # 指定存储聊天记忆的 Keyspace（类似数据库名）
            table: t_ai_chat_memory # 表名
            time-to-live: 1095d # 数据的自动过期时间（1095天 ≈ 3年）
            initialize-schema: true  # 自动初始化表结构
    deepseek:
      api-key: sk-111 # 填写 DeepSeek Api Key, 改成你自己的
      base-url: https://api.deepseek.com # DeepSeek 的请求 URL, 可不填，默认值为 api.deepseek.com
      chat:
        options:
          model: deepseek-chat # 使用哪个模型 chat V3
#          model: deepseek-reasoner # 使用哪个模型 R1
          temperature: 0.8 # 温度值

    ollama:
      base-url: http://localhost:11434 # Ollama 服务的访问地址, 11434 端口是 Ollama 默认的启动端口
      chat:
        options: # 模型参数
          model: qwen3:1.7b # 指定 Ollama 使用的大模型名称，根据你实际安装的来，我运行的是 14.7
          temperature: 0.7 # 温度值
    zhipuai:
      base-url: https://open.bigmodel.cn/api/paas # 智谱 AI 的请求 URL, 可不填，默认值为 open.bigmodel.cn/api/paas
      api-key: 111.111 # 填写智谱 AI 的 API Key, 该成你自己的
      chat:
        options: # 模型参数
          model: glm-4-air # 模型名称，使用智谱 AI 哪个模型
          temperature: 0.7 # 温度值
    openai:
#      base-url: https://api.zhizengzeng.com/v1 # OpenAI 服务的访问地址
#      api-key: sk-111  # 填写智增增的 API Key, 该成你自己的

      base-url: https://dashscope.aliyuncs.com/compatible-mode # OpenAI 服务的访问地址，这里使用的是阿里云百炼
      api-key: sk-111  # 填写智增增的 API Key, 该成你自己的

      chat:
        options:
#          model: gpt-4o # 模型名称
#          model: qwen-turbo # 模型名称
          model: qwen-omni-turbo # 模型名称 全模态模型
          temperature: 0.7 # 温度值

logging:
  level:
    org.springframework.ai.chat.client.advisor: debug